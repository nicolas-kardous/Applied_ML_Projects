{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 3, due February 24 at 11:59pm.\n",
    "\n",
    "### Before You Start\n",
    "\n",
    "Make sure the following libraries load correctly (hit Ctrl-Enter). Note that while you are loading several powerful libraries, including machine learning libraries, the goal of this problem set is to implement several algorithms from scratch. In particular, you should *not* be using any built-in libraries for nearest neighbors, distance metrics, or cross-validation -- your mission is to write those algorithms in Python! Part 1 will be relatively easy; Part 2 will take more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction to the assignment\n",
    "\n",
    "For this assignment, you will be using the [Boston Housing Prices Data Set](http://www.kellogg.northwestern.edu/faculty/weber/emp/_session_3/boston.htm).  Please read about the dataset carefully before continuing.  Use the following commands to load the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Boston housing data set\n",
    "data = np.loadtxt('data.txt')\n",
    "target = np.loadtxt('target.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[:,12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side note: \n",
    "You can use the IPython to easily debug your code. Just add the line IPython.embed() as a break point at some place in\n",
    "your code and it will give you access to a Python terminal where you can view the values that specific variables get, their dimensions etc. The pdb package in Python is also similar to IPython. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Experimental Setup\n",
    "\n",
    "The goal of the next few sections is to design an experiment to predict the median home value for an instance in the data.\n",
    "Before beginning the \"real\" work, refamiliarize yourself with the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Begin by writing a function to compute the Root Mean Squared Error for a list of numbers\n",
    "\n",
    "You can find the sqrt function in the Numpy package. Furthermore the details of RMSE can be found on [Wikipedia](http://en.wikipedia.org/wiki/Root-mean-square_deviation). Do not use a built-in function (other than sqrt) to compute RMSE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "compute_rmse\n",
    "\n",
    "Given two arrays, one of actual values and one of predicted values,\n",
    "compute the Roote Mean Squared Error\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "predictions : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "yvalues : array\n",
    "    Array of numerical values corresponding to the actual values for each of the N observations\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Root Mean Squared Error of the prediction\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print(compute_rmse((2,2,3),(0,2,6)))\n",
    "2.08\n",
    "\"\"\"\n",
    "def compute_rmse(predictions, observed):\n",
    "    rmse = np.sqrt(np.sum((predictions - observed)**2)/len(predictions))\n",
    "    return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Divide your data into training and testing datasets\n",
    "\n",
    "Randomly select 80% of the data and put this in a training dataset (call this \"bdata_train\"), and place the remaining 20% in a testing dataset (call this \"bdata_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# leave the following line untouched, it will help ensure that your \"random\" split is the same \"random\" split used by the rest of the class\n",
    "np.random.seed(seed=13579)\n",
    "\n",
    "bdata_train, bdata_test = train_test_split(target, test_size=0.2)\n",
    "ind_train, ind_test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use a very bad baseline for prediction, and compute RMSE\n",
    "\n",
    "Create a model that predicts, for every observation x_i, that the median home value is the average (mean) of the median values for all instances in the training set.  Specifically, do the following:\n",
    "1. Compute the RMSE of the training set.\n",
    "2. Now compute the RMSE on the test data set (but use the model you trained on the training set!).\n",
    "3. How does RMSE compare for training vs. testing datasets? Is this what you expected, and why?\n",
    "4. Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in blue and the test instances in red. Make sure to label your axes appropriately, and add a legend to your figure to make clear which dots are which.\n",
    "5. Add code to your function to measure the running time of your algorithm. How long does it take to compute the predicted values for the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.313825039697363"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the RMSE of the training set.\n",
    "\n",
    "pred_train=[]\n",
    "\n",
    "for i in range(len(bdata_train)):\n",
    "    pred_train.append(np.mean(target))\n",
    "\n",
    "compute_rmse(pred_train,bdata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.671777143045508"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now compute the RMSE on the test data set (but use the model you trained on the training set!)\n",
    "\n",
    "import time\n",
    "\n",
    "pred_test=[]\n",
    "\n",
    "t_start = time.time()\n",
    "for i in range(len(bdata_test)):\n",
    "    pred_test.append(np.mean(target))\n",
    "t_end = time.time()\n",
    "t_test_baseline = t_end - t_start\n",
    "\n",
    "compute_rmse(pred_test,bdata_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does RMSE compare for training vs. testing datasets? Is this what you expected, and why?\n",
    "\n",
    "The RMSE on the training set is higher than the RMSE on the testing set. Normally, the RMSE on the testing set should be higher because the model is trained on the training set. However, because the model is a bad baseline model, the RMSE on the training set was higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a20594350>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot that shows the true value of each instance on the x-axis and the \n",
    "#predicted value of each instance on the y-axis. Color the training instances in blue and the \n",
    "#test instances in red. Make sure to label your axes appropriately, and add a legend to your \n",
    "#figure to make clear which dots are which.\n",
    "\n",
    "# scatter data\n",
    "plt.scatter(bdata_train, pred_train, c='C0', label='train')\n",
    "plt.scatter(bdata_test, pred_test, c = 'C3',label='test')\n",
    "plt.title(\"Scatter plot that shows true value and predicted value for median house value\")\n",
    "plt.xlabel(\"Observed median value\")\n",
    "plt.ylabel(\"Predicted median value\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to compute predicted values for test data =  0.0014309883117675781\n"
     ]
    }
   ],
   "source": [
    "# Add code to your function to measure \n",
    "#the running time of your algorithm. How long does it take to compute the predicted values for the test data?\n",
    "\n",
    "print('time to compute predicted values for test data = ',t_test_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Use local linear regression for prediction, and compute RMSE.\n",
    "\n",
    "Create a model that predicts, for every observation of nitric oxide concentration the median home value using local linear regression\n",
    "with Epanechnikov kernels (https://en.wikipedia.org/wiki/Kernel_(statistics)).\n",
    "1. Create a scatter plot of the test and training data sets (use different colors for the two). Add on that plot the fit\n",
    "that you get from the local linear regression.\n",
    "2. Tune the smoothing parameter (the window that Epanechnikov kernels are nonegative) so that the RMSE for the test set is low. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a function that implements the Epanechnikov kernel which you will need to weight the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epan_ker(target, data_x, gamma):\n",
    "    '''\n",
    "    Compute the epanechnikov weights. data_x denote the predictors (nitric oxide levels in our case)\n",
    "    and target denotes the house median value. The gamma parameter controls the smoothing. \n",
    "    Inputs: predictors, targets and smoothing parameter gamma \n",
    "    '''\n",
    "    # your code here\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the main code for local linear regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here you should include the main code for local linear regression\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_lowess(x_train, y_train, x_test, y_test, x_plot, y_plot):\n",
    "    '''\n",
    "    Scatter plot of data points along with lowess fit.\n",
    "    Inputs: training and test data points, lowess fitted values\n",
    "    '''\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Nearest Neighbors: Distance function\n",
    "Let's try and build a machine learning algorithm to beat the \"Average Value\" baseline that you computed above.  Soon you will implement the Nearest Neighbor algorithm, but first you need to create a distance metric to measure the distance (and similarity) between two instances.  Write a generic function to compute the L-Norm distance (called the [*p*-norm][1] distance on Wikipedia). Verify that your function works by computing the Euclidean distance between the points (3,4) and (6,8).\n",
    "[1]: https://en.wikipedia.org/wiki/Norm_(mathematics)#p-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "distance\n",
    "\n",
    "Given two instances and a value for L, return the L-Norm distance between them\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x1, x2 : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "L: int\n",
    "    Value of L to use in computing distances\n",
    "\n",
    "Returns\n",
    "-------\n",
    "dist : int\n",
    "    The L-norm distance between instances\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print(distance((3,4),(6,8),2))\n",
    "5\n",
    "\n",
    "\"\"\"\n",
    "def distance(x1, x2, L):\n",
    "    x1 = np.array(x1)\n",
    "    x2 = np.array(x2)\n",
    "    dist = (np.sum((x1 - x2)**L))**(1/L)    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(distance((3,4),(6,8),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Nearest Neighbor algorithm\n",
    "\n",
    "Your next task is to implement a basic nearest neighbor algorithm from scratch.  Your simple model will use two input features (CRIM and RM) and a single output (MEDV).  In other words, you are modelling the relationship between median home value and crime rates and house size.\n",
    "\n",
    "Use your training data (bdata_train) to \"fit\" your model, although as you know, with Nearest Neighbors there is no real training, you just need to keep your training data in memory.  Write a function that predicts the median home value using the nearest neighbor algorithm we discussed in class.  Since this is a small dataset, you can simply compare your test instance to every instance in the training set, and return the MEDV value of the closest training instance.  Have your function take L as an input, where L is passed to the distance function.\n",
    "\n",
    "Make sure to do the following\n",
    "1. Fill in the function specification below\n",
    "2. Use your algorithm to predict the median home value of every instance in the test set. Report the RMSE (\"test RMSE\")\n",
    "3. Use your algorithm to predict the median home value of every instance in the training set and report the training RMSE.\n",
    "4. Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in blue and the test instances in red. \n",
    "5. Report an estimate of the total time taken by your code to predict the nearest neighbors for all the values in the test data set.\n",
    "6. How does the performance (test RMSE and total runtime) of your nearest neighbors algorithm compare to the baseline in part 1.4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6980009761887515"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train = {'CRIM': ind_train[:,0], 'RM': ind_train[:,5]}\n",
    "d_test = {'CRIM': ind_test[:,0], 'RM': ind_test[:,5]}\n",
    "CRIM_RM_train = pd.DataFrame(data=d_train)\n",
    "CRIM_RM_test = pd.DataFrame(data=d_test)\n",
    "\n",
    "distance(CRIM_RM_test.iloc[0,:],CRIM_RM_train.iloc[0,:],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 13.88248085975647 seconds\n",
      "The RMSE is: 14.037055302613417 \n"
     ]
    }
   ],
   "source": [
    "# 2. Use your algorithm to predict the median home value of every instance in the test set. \n",
    "# Report the RMSE (\"test RMSE\")\n",
    "\n",
    "\"\"\"\n",
    "# write your function specification here!\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "def nneighbor(x_train,x_test,y_train,y_test, L):\n",
    "\n",
    "    start_time = time.time()\n",
    "    predicted_y = np.zeros(len(x_test))\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        dist=[]\n",
    "        for j in range(len(x_train)):\n",
    "            dist.append(distance(x_test.iloc[i,:], x_train.iloc[j,:], L))\n",
    "        predicted_y[i] = y_train[np.argmin(dist)]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    rmse = compute_rmse(predicted_y, y_test)\n",
    "    \n",
    "    t_time = end_time - start_time\n",
    "\n",
    "    print(\"Total Time taken for code to predict nearest neighbors: {} seconds\".format(t_time))\n",
    "    print(\"The RMSE is: {} \".format(rmse))\n",
    "    return rmse, predicted_y, t_time\n",
    "\n",
    "rmse_test, predicted_y_test, t_time_test = nneighbor(CRIM_RM_train,CRIM_RM_test,bdata_train,bdata_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 61.26075792312622 seconds\n",
      "The RMSE is: 0.0 \n"
     ]
    }
   ],
   "source": [
    "# Use your algorithm to predict the median home value of every instance in\n",
    "# the training set and report the training RMSE.\n",
    "\n",
    "rmse_train, predicted_y_train, t_time_train = nneighbor(CRIM_RM_train,CRIM_RM_train,bdata_train,bdata_train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a20159210>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot that shows the true value of each instance on the x-axis and the \n",
    "# predicted value of each instance on the y-axis. Color the training instances in blue and \n",
    "# the test instances in red. \n",
    "\n",
    "plt.scatter(bdata_train, predicted_y_train, c='C0', label='train')\n",
    "plt.scatter(bdata_test, predicted_y_test, c = 'C3',label='test')\n",
    "plt.title(\"Scatter plot that shows true value and predicted value for median house value\")\n",
    "plt.xlabel(\"Observed median value\")\n",
    "plt.ylabel(\"Predicted median value\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How does the performance (test RMSE and total runtime) of your nearest neighbors algorithm compare to the baseline in part 1.4?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Results and Normalization\n",
    "\n",
    "If you were being astute, you would have noticed that we never normalized our features -- a big no-no with Nearest Neighbor algorithms.  Write a generic normalization function that takes as input an array of values for a given feature, and returns the normalized array (subtract the mean and divide by the standard deviation).\n",
    "\n",
    "Re-run the Nearest Neighbor algorithm on the normalized dataset (still just using CRIM and RM as input), and compare the RMSE from this method with your previous RMSE evaluations. What do you observe?\n",
    "\n",
    "*NOTE*: To normalize properly, best practice is to compute the mean and standard deviation on the training set, and use these values to normalize the testing dataset. However, for this problem set, it is okay if you separately normalize each dataset using the respective mean and standard deviation.\n",
    "\n",
    "*NOTE 2*: In this case, there might not be a major impact on RMSE; don't get confused if you find that to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 13.956018924713135 seconds\n",
      "The RMSE is: 13.58640468103548 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# write your function specification here!\n",
    "\"\"\"\n",
    "def normalize(raw_data):\n",
    "    normalized_data = (raw_data - np.mean(raw_data, axis=0))/np.std(raw_data, axis=0)\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "CRIM_RM_train_norm = CRIM_RM_train.copy()\n",
    "for col in CRIM_RM_train.columns:\n",
    "    CRIM_RM_train_norm[col] = normalize(CRIM_RM_train[col])\n",
    "    \n",
    "CRIM_RM_test_norm = CRIM_RM_test.copy()\n",
    "for col in CRIM_RM_test.columns:\n",
    "    CRIM_RM_test_norm[col] = normalize(CRIM_RM_test[col])\n",
    "    \n",
    "\n",
    "rmse_test, predicted_y_test, t_time_test = nneighbor(CRIM_RM_train_norm,CRIM_RM_test_norm,bdata_train,bdata_test,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our RMSE, we see that it has decreased to 13.586, compared to the previous RMSE of 14.037. From this, it looks like that normalizing the data improved our model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Optimization\n",
    "\n",
    "A lot of the decisions we've made so far have been arbitrary.  Try to increase the performance of your nearest neighbor algorithm by adding features that you think might be relevant, and by using different values of L in the distance function.  Try a model that uses a different set of 2 features, then try at least one model that uses more than 4 features, then try using a different value of L.  If you're having fun, try a few different combinations of features and L!\n",
    "\n",
    "What combination of features and distance function provide the lowest RMSE?  Do your decisions affect the running time of the algorithm?\n",
    "\n",
    "*NOTE:* For this and all subsequent questions, you should use normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 13.623626947402954 seconds\n",
      "The RMSE is: 11.584671244499658 \n"
     ]
    }
   ],
   "source": [
    "# Model that uses a different set of 2 features using tax and distance\n",
    "\n",
    "d_train_2 = {'DIS': ind_train[:,7], 'TAX': ind_train[:,9]}\n",
    "d_test_2 = {'DIS': ind_test[:,7], 'TAX': ind_test[:,9]}\n",
    "DIS_TAX_train = pd.DataFrame(data=d_train_2)\n",
    "DIS_TAX_test = pd.DataFrame(data=d_test_2)\n",
    "\n",
    "DIS_TAX_train_norm = DIS_TAX_train.copy()\n",
    "for col in DIS_TAX_train.columns:\n",
    "    DIS_TAX_train_norm[col] = normalize(DIS_TAX_train[col])\n",
    "    \n",
    "DIS_TAX_test_norm = DIS_TAX_test.copy()\n",
    "for col in DIS_TAX_test.columns:\n",
    "    DIS_TAX_test_norm[col] = normalize(DIS_TAX_test[col])\n",
    "    \n",
    "\n",
    "rmse_test, predicted_y_test, t_time_test = nneighbor(DIS_TAX_train_norm,DIS_TAX_test_norm,bdata_train,bdata_test,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolaskardous/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 14.461294651031494 seconds\n",
      "The RMSE is: 11.925956203699098 \n"
     ]
    }
   ],
   "source": [
    "# Model that uses more than 4 features using CRIME, RM, nox, tax and distance\n",
    "\n",
    "d_train_3 = {'CRIM': ind_train[:,0],'NOX': ind_train[:,4],'RM': ind_train[:,5], 'DIS': ind_train[:,7], 'TAX': ind_train[:,9]}\n",
    "d_test_3 = {'CRIM': ind_test[:,0],'NOX': ind_test[:,4],'RM': ind_test[:,5], 'DIS': ind_test[:,7], 'TAX': ind_test[:,9]}\n",
    "extra_features_train = pd.DataFrame(data=d_train_3)\n",
    "extra_features_test = pd.DataFrame(data=d_test_3)\n",
    "\n",
    "extra_features_train_norm = extra_features_train.copy()\n",
    "for col in extra_features_train.columns:\n",
    "    extra_features_train_norm[col] = normalize(extra_features_train[col])\n",
    "    \n",
    "extra_features_test_norm = extra_features_test.copy()\n",
    "for col in extra_features_test.columns:\n",
    "    extra_features_test_norm[col] = normalize(extra_features_test[col])\n",
    "    \n",
    "\n",
    "rmse_test, predicted_y_test, t_time_test = nneighbor(extra_features_train_norm,extra_features_test_norm,bdata_train,bdata_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolaskardous/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 14.129817962646484 seconds\n",
      "The RMSE is: 11.361924719576932 \n"
     ]
    }
   ],
   "source": [
    "# Model that uses a different value of L, where L = 3\n",
    "\n",
    "rmse_test, predicted_y_test, t_time_test = nneighbor(DIS_TAX_train_norm,DIS_TAX_test_norm,bdata_train,bdata_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 13.247688055038452 seconds\n",
      "The RMSE is: 9.614322445104042 \n"
     ]
    }
   ],
   "source": [
    "# Model that uses a different value of L, where L = 1\n",
    "\n",
    "rmse_test, predicted_y_test, t_time_test = nneighbor(DIS_TAX_train_norm,DIS_TAX_test_norm,bdata_train,bdata_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 13.65916895866394 seconds\n",
      "The RMSE is: 11.689856504595735 \n"
     ]
    }
   ],
   "source": [
    "# Model that uses a different value of L, where L = 4\n",
    "\n",
    "rmse_test, predicted_y_test, t_time_test = nneighbor(DIS_TAX_train_norm,DIS_TAX_test_norm,bdata_train,bdata_test,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look for the number of features and L value to lead to the lowest RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all the variables\n",
    "\n",
    "data_train = {'CRIM': ind_train[:,0],'ZN':ind_train[:,1],'INDUS':ind_train[:,2],'CHAS':ind_train[:,3],'NOX': ind_train[:,4],'RM': ind_train[:,5], 'AGE':ind_train[:,6],'DIS': ind_train[:,7],'RAD':ind_train[:,8],'TAX': ind_train[:,9],'PTRATIO':ind_train[:,10],'BLACK':ind_train[:,11],'LSTAT':ind_train[:,12]}\n",
    "\n",
    "data_test = {'CRIM': ind_test[:,0],'ZN':ind_test[:,1],'INDUS':ind_test[:,2],'CHAS':ind_test[:,3],'NOX': ind_test[:,4],'RM': ind_test[:,5], 'AGE':ind_test[:,6],'DIS': ind_test[:,7],'RAD':ind_test[:,8],'TAX': ind_test[:,9],'PTRATIO':ind_test[:,10],'BLACK':ind_test[:,11],'LSTAT':ind_test[:,12]}\n",
    "\n",
    "all_train = pd.DataFrame(data=data_train)\n",
    "all_test = pd.DataFrame(data=data_test)\n",
    "\n",
    "# Normalize the values\n",
    "\n",
    "all_train_norm = all_train.copy()\n",
    "for col in all_train.columns:\n",
    "    all_train_norm[col] = normalize(all_train[col])\n",
    "\n",
    "all_test_norm = all_test.copy()\n",
    "for col in all_test.columns:\n",
    "    all_test_norm[col] = normalize(all_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 14.232553958892822 seconds\n",
      "The RMSE is: 14.314105890728221 \n",
      "Total Time taken for code to predict nearest neighbors: 13.886659145355225 seconds\n",
      "The RMSE is: 11.575104285305004 \n",
      "Total Time taken for code to predict nearest neighbors: 14.231765985488892 seconds\n",
      "The RMSE is: 11.734008726105234 \n",
      "Total Time taken for code to predict nearest neighbors: 14.631655216217041 seconds\n",
      "The RMSE is: 12.137306772355823 \n",
      "Total Time taken for code to predict nearest neighbors: 13.905489921569824 seconds\n",
      "The RMSE is: 13.58640468103548 \n",
      "Total Time taken for code to predict nearest neighbors: 18.07366967201233 seconds\n",
      "The RMSE is: 11.962572351083272 \n",
      "Total Time taken for code to predict nearest neighbors: 17.214189767837524 seconds\n",
      "The RMSE is: 12.095360478218051 \n",
      "Total Time taken for code to predict nearest neighbors: 18.032721281051636 seconds\n",
      "The RMSE is: 13.486154846694427 \n",
      "Total Time taken for code to predict nearest neighbors: 16.16620397567749 seconds\n",
      "The RMSE is: 12.686371412182567 \n",
      "Total Time taken for code to predict nearest neighbors: 16.113395929336548 seconds\n",
      "The RMSE is: 12.16083798067209 \n",
      "Total Time taken for code to predict nearest neighbors: 15.217407941818237 seconds\n",
      "The RMSE is: 13.616699666362681 \n",
      "Total Time taken for code to predict nearest neighbors: 15.315854787826538 seconds\n",
      "The RMSE is: 12.257918609105339 \n",
      "Total Time taken for code to predict nearest neighbors: 15.017639875411987 seconds\n",
      "The RMSE is: 10.923418806919955 \n",
      "Total Time taken for code to predict nearest neighbors: 15.828228950500488 seconds\n",
      "The RMSE is: 10.661475452465735 \n",
      "Total Time taken for code to predict nearest neighbors: 13.546660900115967 seconds\n",
      "The RMSE is: 13.518879318908638 \n",
      "Total Time taken for code to predict nearest neighbors: 13.707193851470947 seconds\n",
      "The RMSE is: 14.49440392351611 \n",
      "Total Time taken for code to predict nearest neighbors: 14.364136934280396 seconds\n",
      "The RMSE is: 12.450757910626148 \n",
      "Total Time taken for code to predict nearest neighbors: 13.05393385887146 seconds\n",
      "The RMSE is: 12.52668132819061 \n",
      "Total Time taken for code to predict nearest neighbors: 13.445097923278809 seconds\n",
      "The RMSE is: 11.95404189582163 \n",
      "Total Time taken for code to predict nearest neighbors: 12.956984043121338 seconds\n",
      "The RMSE is: 13.69551951924281 \n",
      "Total Time taken for code to predict nearest neighbors: 13.754480123519897 seconds\n",
      "The RMSE is: 12.551669680353521 \n",
      "Total Time taken for code to predict nearest neighbors: 13.427103996276855 seconds\n",
      "The RMSE is: 13.264259807290193 \n",
      "Total Time taken for code to predict nearest neighbors: 13.42621374130249 seconds\n",
      "The RMSE is: 14.060618065794865 \n",
      "Total Time taken for code to predict nearest neighbors: 12.91750693321228 seconds\n",
      "The RMSE is: 11.647026886468394 \n",
      "Total Time taken for code to predict nearest neighbors: 13.164494276046753 seconds\n",
      "The RMSE is: 14.150493651750644 \n",
      "Total Time taken for code to predict nearest neighbors: 13.339153051376343 seconds\n",
      "The RMSE is: 13.053975429339674 \n",
      "Total Time taken for code to predict nearest neighbors: 13.739190816879272 seconds\n",
      "The RMSE is: 12.181483054692672 \n",
      "Total Time taken for code to predict nearest neighbors: 13.253566026687622 seconds\n",
      "The RMSE is: 10.745637509715097 \n",
      "Total Time taken for code to predict nearest neighbors: 14.905163049697876 seconds\n",
      "The RMSE is: 11.021796586763886 \n",
      "Total Time taken for code to predict nearest neighbors: 15.336303949356079 seconds\n",
      "The RMSE is: 12.679402781754384 \n",
      "Total Time taken for code to predict nearest neighbors: 14.383728265762329 seconds\n",
      "The RMSE is: 12.529044687617397 \n",
      "Total Time taken for code to predict nearest neighbors: 15.453239679336548 seconds\n",
      "The RMSE is: 12.319588260244771 \n",
      "Total Time taken for code to predict nearest neighbors: 14.049110174179077 seconds\n",
      "The RMSE is: 11.419621057549993 \n",
      "Total Time taken for code to predict nearest neighbors: 13.773017168045044 seconds\n",
      "The RMSE is: 13.976752406876829 \n",
      "Total Time taken for code to predict nearest neighbors: 13.820090770721436 seconds\n",
      "The RMSE is: 13.319644934324284 \n",
      "Total Time taken for code to predict nearest neighbors: 13.655648946762085 seconds\n",
      "The RMSE is: 11.27831947570552 \n",
      "Total Time taken for code to predict nearest neighbors: 12.998678922653198 seconds\n",
      "The RMSE is: 12.701462784370355 \n",
      "Total Time taken for code to predict nearest neighbors: 13.780730962753296 seconds\n",
      "The RMSE is: 12.171334049684924 \n",
      "Total Time taken for code to predict nearest neighbors: 12.841949939727783 seconds\n",
      "The RMSE is: 11.986561102285489 \n",
      "Total Time taken for code to predict nearest neighbors: 12.959747076034546 seconds\n",
      "The RMSE is: 12.229224078764254 \n",
      "Total Time taken for code to predict nearest neighbors: 12.896038293838501 seconds\n",
      "The RMSE is: 12.166975553425225 \n",
      "Total Time taken for code to predict nearest neighbors: 12.869035005569458 seconds\n",
      "The RMSE is: 13.427141812571355 \n",
      "Total Time taken for code to predict nearest neighbors: 12.879532098770142 seconds\n",
      "The RMSE is: 14.266710188682012 \n",
      "Total Time taken for code to predict nearest neighbors: 12.892375230789185 seconds\n",
      "The RMSE is: 13.209692668346106 \n",
      "Total Time taken for code to predict nearest neighbors: 12.750094890594482 seconds\n",
      "The RMSE is: 12.452773531525054 \n",
      "Total Time taken for code to predict nearest neighbors: 12.922508716583252 seconds\n",
      "The RMSE is: 11.686895627657702 \n",
      "Total Time taken for code to predict nearest neighbors: 12.965191125869751 seconds\n",
      "The RMSE is: 14.0304256220991 \n",
      "Total Time taken for code to predict nearest neighbors: 13.70990800857544 seconds\n",
      "The RMSE is: 11.147698258859908 \n",
      "Total Time taken for code to predict nearest neighbors: 13.928508758544922 seconds\n",
      "The RMSE is: 10.836765670442377 \n",
      "Total Time taken for code to predict nearest neighbors: 12.925475835800171 seconds\n",
      "The RMSE is: 12.69763757554924 \n",
      "Total Time taken for code to predict nearest neighbors: 13.018594980239868 seconds\n",
      "The RMSE is: 11.765636237723458 \n",
      "Total Time taken for code to predict nearest neighbors: 12.768548965454102 seconds\n",
      "The RMSE is: 10.906114492949968 \n",
      "Total Time taken for code to predict nearest neighbors: 12.76699185371399 seconds\n",
      "The RMSE is: 12.169094573759299 \n",
      "Total Time taken for code to predict nearest neighbors: 12.806962251663208 seconds\n",
      "The RMSE is: 13.597300049180756 \n",
      "Total Time taken for code to predict nearest neighbors: 12.807175159454346 seconds\n",
      "The RMSE is: 12.169404741592988 \n",
      "Total Time taken for code to predict nearest neighbors: 15.424123764038086 seconds\n",
      "The RMSE is: 11.003715949890852 \n",
      "Total Time taken for code to predict nearest neighbors: 13.166631937026978 seconds\n",
      "The RMSE is: 13.566430599670875 \n",
      "Total Time taken for code to predict nearest neighbors: 13.169986963272095 seconds\n",
      "The RMSE is: 10.471904521801443 \n",
      "Total Time taken for code to predict nearest neighbors: 12.91783094406128 seconds\n",
      "The RMSE is: 13.355049716911443 \n",
      "Total Time taken for code to predict nearest neighbors: 12.995625019073486 seconds\n",
      "The RMSE is: 13.098622888251553 \n",
      "Total Time taken for code to predict nearest neighbors: 12.94762897491455 seconds\n",
      "The RMSE is: 12.623534665496047 \n",
      "Total Time taken for code to predict nearest neighbors: 12.91566514968872 seconds\n",
      "The RMSE is: 11.703728247954187 \n",
      "Total Time taken for code to predict nearest neighbors: 12.912156105041504 seconds\n",
      "The RMSE is: 11.617139974041399 \n",
      "Total Time taken for code to predict nearest neighbors: 12.87244987487793 seconds\n",
      "The RMSE is: 15.246449281267902 \n",
      "Total Time taken for code to predict nearest neighbors: 14.46874189376831 seconds\n",
      "The RMSE is: 11.584671244499658 \n",
      "Total Time taken for code to predict nearest neighbors: 13.134450197219849 seconds\n",
      "The RMSE is: 12.488194425136086 \n",
      "Total Time taken for code to predict nearest neighbors: 13.07203197479248 seconds\n",
      "The RMSE is: 10.38662412838328 \n",
      "Total Time taken for code to predict nearest neighbors: 13.01987099647522 seconds\n",
      "The RMSE is: 13.165272946836534 \n",
      "Total Time taken for code to predict nearest neighbors: 13.155591249465942 seconds\n",
      "The RMSE is: 11.725295263642952 \n",
      "Total Time taken for code to predict nearest neighbors: 12.918633937835693 seconds\n",
      "The RMSE is: 11.654360456372492 \n",
      "Total Time taken for code to predict nearest neighbors: 12.945200681686401 seconds\n",
      "The RMSE is: 12.059732868631258 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 13.085174083709717 seconds\n",
      "The RMSE is: 13.4402417403563 \n",
      "Total Time taken for code to predict nearest neighbors: 13.312041282653809 seconds\n",
      "The RMSE is: 11.800660499959065 \n",
      "Total Time taken for code to predict nearest neighbors: 12.943401098251343 seconds\n",
      "The RMSE is: 12.503826865184507 \n",
      "Total Time taken for code to predict nearest neighbors: 13.205582857131958 seconds\n",
      "The RMSE is: 13.108742031448282 \n",
      "Total Time taken for code to predict nearest neighbors: 13.28959584236145 seconds\n",
      "The RMSE is: 11.31731278296447 \n",
      "Total Time taken for code to predict nearest neighbors: 13.372032642364502 seconds\n",
      "The RMSE is: 12.076711505385633 \n",
      "Total Time taken for code to predict nearest neighbors: 13.208961248397827 seconds\n",
      "The RMSE is: 12.10526542378944 \n"
     ]
    }
   ],
   "source": [
    "# We first find the two features with the lowest RMSE\n",
    "\n",
    "\n",
    "rmse_values = []\n",
    "\n",
    "for i in range(all_train.shape[1]):\n",
    "    for j in range(i+1,all_train.shape[1]):\n",
    "        train = {'col1': ind_train[:,i],'col2': ind_train[:,j]}\n",
    "        test = {'col1': ind_test[:,i],'col2': ind_test[:,j]}\n",
    "        two_features_train = pd.DataFrame(data=train)\n",
    "        two_features_test = pd.DataFrame(data=test)\n",
    "        two_features_norm_train = two_features_train.copy()\n",
    "        for col in two_features_norm_train.columns:\n",
    "            two_features_norm_train[col] = normalize(two_features_train[col])\n",
    "        two_features_norm_test = two_features_test.copy()\n",
    "        for col in two_features_norm_test.columns:\n",
    "            two_features_norm_test[col] = normalize(two_features_test[col])\n",
    "        rmse_test, predicted_y_test, t_time_test = nneighbor(two_features_norm_train,two_features_norm_test,bdata_train,bdata_test,2)\n",
    "        rmse_values.append(rmse_test)\n",
    "        if rmse_values[-1] > rmse_test:\n",
    "            i1 = i\n",
    "            i2 = j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 14.000190258026123 seconds\n",
      "The RMSE is: 8.66443598743693 \n",
      "Total Time taken for code to predict nearest neighbors: 13.776104927062988 seconds\n",
      "The RMSE is: 15.246449281267902 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolaskardous/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 13.314141988754272 seconds\n",
      "The RMSE is: 11.40194771803072 \n",
      "Total Time taken for code to predict nearest neighbors: 13.55289912223816 seconds\n",
      "The RMSE is: 15.287458014628188 \n"
     ]
    }
   ],
   "source": [
    "# From this, we find that the features with the lowest RMSE are DIS and RAD. From this, we change our value for\n",
    "# L and see which L value gives us the lowest RMSE\n",
    "\n",
    "train = {'dis': ind_train[:,7],'rad': ind_train[:,8]}\n",
    "test = {'dis': ind_test[:,7],'rad': ind_test[:,8]}\n",
    "DIS_RAD_train = pd.DataFrame(data=train)\n",
    "DIS_RAD_test = pd.DataFrame(data=test)\n",
    "DIS_RAD_norm_train = DIS_RAD_train.copy()\n",
    "for col in DIS_RAD_norm_train.columns:\n",
    "    DIS_RAD_norm_train[col] = normalize(DIS_RAD_train[col])\n",
    "DIS_RAD_norm_test = DIS_RAD_test.copy()\n",
    "for col in DIS_RAD_norm_test.columns:\n",
    "    DIS_RAD_norm_test[col] = normalize(DIS_RAD_test[col])\n",
    "\n",
    "for L in range(1,5):\n",
    "    rmse_test, predicted_y_test, t_time_test = nneighbor(DIS_RAD_norm_train,DIS_RAD_norm_test,bdata_train,bdata_test,L)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first look at changing our two features to tax and dis. We find that the RMSE reduces to 11.58. From adding more features, such as CRIM, NOX and RM, our RMSE is 11.926. This is lower than our very first RMSE value, but higher than 11.58. I then update the values for L to L = 1,3,4. When L = 3, the RMSE reduces to 11.36. When L = 4, the RMSE increases to 13.98. Finally, when L = 1, we have the lowest RMSE of 9.614. Thus, we have the lowest RMSE for 2 features (tax,dis), and a L value = 1. \n",
    "\n",
    "From implementing the algorithm above, we find that the two features that give us the lowest value for RMSE are DIS and RAD. We then iteravely run the nearest neighbor function again across different L values, and we find a minimum RMSE value of 8.66 when the L value = 1.\n",
    "\n",
    "Overall, we see that the running time of the algorithms does not change too much from our decisions. For example, when using 2 features or 5 features, the run times are about the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Cross-Validation\n",
    "\n",
    "The more you tinkered with your features and distance function, the higher the risk that you overfit your training data.  One solution to this sort of overfitting is to use cross-validation (see K-fold [cross-validation][1].  Here you must implement a simple k-fold cross-validation algorithm yourself.  The function you write here will be used several more times in this problem set, so do your best to write efficient code! (Note that the sklearn package has a built-in [K-fold][2] iterator -- you should *not* be invoking that or any related algorithms in this section of the problem set.)\n",
    "\n",
    "Use 10-fold cross-validation and report the average RMSE for Nearest Neighbors using Euclidean distance with CRIM and RM input features, as well as the total running time for the full run of 10 folds.  In other words, randomly divide your dataset into 10 equally-sized samples, and for each of 10 iterations (the \"folds\"), use 9 samples as \"training data\" (even though there is no training in k-NN!), and the remaining 1 sample for testing.  Compute the RMSE of that particular test set, then move on to the next iteration.  Report the average RMSE across the 10 iterations. What do you observe?\n",
    "[1]: http://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "[2]: http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.218960</td>\n",
       "      <td>6.875396</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.141576</td>\n",
       "      <td>6.499894</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380457</td>\n",
       "      <td>7.263489</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.313563</td>\n",
       "      <td>7.209732</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330105</td>\n",
       "      <td>7.184111</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.205345</td>\n",
       "      <td>6.895386</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.120722</td>\n",
       "      <td>6.313574</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.226099</td>\n",
       "      <td>7.199346</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>7.065029</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.183073</td>\n",
       "      <td>6.353149</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        RM  MEDV\n",
       "0    0.218960  6.875396  24.0\n",
       "1    0.141576  6.499894  21.6\n",
       "2    0.380457  7.263489  34.7\n",
       "3    0.313563  7.209732  33.4\n",
       "4    0.330105  7.184111  36.2\n",
       "..        ...       ...   ...\n",
       "501  0.205345  6.895386  22.4\n",
       "502  0.120722  6.313574  20.6\n",
       "503  0.226099  7.199346  23.9\n",
       "504  0.139833  7.065029  22.0\n",
       "505  0.183073  6.353149  11.9\n",
       "\n",
       "[506 rows x 3 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will go back to the original data file, and divide the whole set into training and testing sets. \n",
    "np.random.seed(seed=13579)\n",
    "\n",
    "d_25_train = {'CRIM': data[:,0], 'RM': data[:,5]}\n",
    "d_25_test = {'MEDV': target}\n",
    "CV_train = pd.DataFrame(data=d_25_train)\n",
    "CV_test = pd.DataFrame(data=d_25_test)\n",
    "CV_train_norm = CV_train.copy()\n",
    "for col in CV_train_norm.columns:\n",
    "    CV_train_norm[col] = normalize(CV_train[col])\n",
    "for col in CV_test_norm.columns:\n",
    "    CV_test_norm[col] = normalize(CV_test[col])\n",
    "\n",
    "CV_train[\"MEDV\"]= CV_test[\"MEDV\"]\n",
    "\n",
    "CV_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>fold_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.218960</td>\n",
       "      <td>6.875396</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.141576</td>\n",
       "      <td>6.499894</td>\n",
       "      <td>21.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380457</td>\n",
       "      <td>7.263489</td>\n",
       "      <td>34.7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.313563</td>\n",
       "      <td>7.209732</td>\n",
       "      <td>33.4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330105</td>\n",
       "      <td>7.184111</td>\n",
       "      <td>36.2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        RM  MEDV  fold_number\n",
       "0  0.218960  6.875396  24.0          4.0\n",
       "1  0.141576  6.499894  21.6          2.0\n",
       "2  0.380457  7.263489  34.7          5.0\n",
       "3  0.313563  7.209732  33.4          7.0\n",
       "4  0.330105  7.184111  36.2          7.0"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column of fold numbers\n",
    " \n",
    "# Number of values per fold\n",
    "num_folds = np.int(CV_train.shape[0]/10)\n",
    "fold_index = np.random.choice(range(CV_train.shape[0]), (10, num_folds), replace=False)\n",
    "\n",
    "for i in range(10):\n",
    "    CV_train.loc[fold_index[i],'fold_number'] = i+1\n",
    "    \n",
    "CV_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken for code to predict nearest neighbors: 7.805544376373291 seconds\n",
      "The RMSE is: 85.96121218317015 \n",
      "Total Time taken for code to predict nearest neighbors: 7.677200794219971 seconds\n",
      "The RMSE is: 96.65161560988 \n",
      "Total Time taken for code to predict nearest neighbors: 7.591397047042847 seconds\n",
      "The RMSE is: 85.3822300013299 \n",
      "Total Time taken for code to predict nearest neighbors: 7.259641885757446 seconds\n",
      "The RMSE is: 93.12066795293084 \n",
      "Total Time taken for code to predict nearest neighbors: 7.762005090713501 seconds\n",
      "The RMSE is: 74.62985461596452 \n",
      "Total Time taken for code to predict nearest neighbors: 7.5228941440582275 seconds\n",
      "The RMSE is: 92.95878441546016 \n",
      "Total Time taken for code to predict nearest neighbors: 8.495397090911865 seconds\n",
      "The RMSE is: 114.42058381252912 \n",
      "Total Time taken for code to predict nearest neighbors: 8.745836019515991 seconds\n",
      "The RMSE is: 101.68562336928461 \n",
      "Total Time taken for code to predict nearest neighbors: 8.39854884147644 seconds\n",
      "The RMSE is: 90.70585207140716 \n",
      "Total Time taken for code to predict nearest neighbors: 7.880494832992554 seconds\n",
      "The RMSE is: 91.99012338289366 \n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE values for each fold\n",
    "\n",
    "RMSE_values = np.zeros(10)\n",
    "time_values = np.zeros(10)\n",
    "\n",
    "for i in range(10):\n",
    "    RMSE, predicted_y_test, t_time = nneighbor(CV_train[CV_train['fold_number']!=(i+1)][['RM','CRIM']],CV_train[CV_train['fold_number']==(i+1)][['RM','CRIM']],CV_train[CV_train['fold_number']!=(i+1)][['MEDV']].values,CV_train[CV_train['fold_number']==(i+1)][['MEDV']].values,2)\n",
    "    \n",
    "    RMSE_values[i] = RMSE\n",
    "    time_values[i] = t_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for computation =  7.880494832992554\n",
      "Average RMSE value =  92.75065474148502\n"
     ]
    }
   ],
   "source": [
    "print('Total time for computation = ',np.sum(t_time))\n",
    "print('Average RMSE value = ',np.mean(RMSE_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our RMSE values, we see that there is a big range to them. For example, the minimum RMSE value was found to be 74.629855, and the maximum RMSE value is 114.42059. This goes to show that there is overfitting in the model. Our mean RMSE value was found to be 92.7. This means value is a good estimate to use, because this shows how accurate our model is among a variety of training and testing sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 K-Nearest Neighbors Algorithm\n",
    "\n",
    "Implement the K-Nearest Neighbors algorithm.  Using 10-fold cross validation and L2 normalization, report the RMSE for K=3 and the running time of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could use the folds we created from question 2.5\n",
    "\n",
    "def knneighbor(x, y, fold_number, L, K):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    RMSE_values = np.zeros(10)\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        x_train = x[fold_number!=(i+1)]\n",
    "        x_test = x[fold_number==(i+1)]\n",
    "        y_train = y[fold_number!=(i+1)]\n",
    "        y_test = y[fold_number==(i+1)]\n",
    "        \n",
    "        predicted_y = np.zeros(x_test.shape[0])\n",
    "        \n",
    "        for a in range(len(x_test)):\n",
    "            dist=[]\n",
    "            for b in range(len(x_train)):\n",
    "                dist.append(distance(x_test.iloc[a,:], x_train.iloc[b,:], L))\n",
    "        predicted_y[a] = np.mean(y_train[np.sort(dist)[:K]])\n",
    "        \n",
    "        RMSE_values[i] = compute_rmse(predicted_y, y_test.values)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    RMSE_mean = np.mean(RMSE_values)\n",
    "    t = end_time - start_time\n",
    "    \n",
    "    print(\"Total Time taken for code to predict nearest neighbors: {} seconds\".format(t))\n",
    "    print(\"The RMSE is: {} \", RMSE_mean)\n",
    "    \n",
    "    return RMSE_mean, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_mean, t = knneighbor(CV_train[['CRIM','RM']],CV_train['MEDV'],CV_train['fold_number'], 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Using cross validation to find K\n",
    "\n",
    "What is the best choice of K?  Compute the RMSE for values of K between 1 and 25 using 10-fold cross-validation.  Use the following features in your model, and don't forget to normalize: CRIM, ZN, RM, AGE, DIS, TAX.  Create a graph that shows how RMSE changes as K increases from 1 to 25.  Label your axes, and summarize what you see.  What do you think is a reasonable choice of K for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>TAX</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.218960</td>\n",
       "      <td>18.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.347275</td>\n",
       "      <td>307.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.141576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.9</td>\n",
       "      <td>5.315684</td>\n",
       "      <td>255.0</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.1</td>\n",
       "      <td>5.356935</td>\n",
       "      <td>243.0</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.313563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.103983</td>\n",
       "      <td>226.0</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.264372</td>\n",
       "      <td>234.0</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.205345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.805111</td>\n",
       "      <td>282.0</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.120722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.652694</td>\n",
       "      <td>282.0</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.226099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.348891</td>\n",
       "      <td>284.0</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.783274</td>\n",
       "      <td>275.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.183073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.847304</td>\n",
       "      <td>283.0</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN    RM       DIS    TAX  MEDV\n",
       "0    0.218960  18.0  65.2  4.347275  307.0  24.0\n",
       "1    0.141576   0.0  78.9  5.315684  255.0  21.6\n",
       "2    0.380457   0.0  61.1  5.356935  243.0  34.7\n",
       "3    0.313563   0.0  45.8  6.103983  226.0  33.4\n",
       "4    0.330105   0.0  54.2  6.264372  234.0  36.2\n",
       "..        ...   ...   ...       ...    ...   ...\n",
       "501  0.205345   0.0  69.1  2.805111  282.0  22.4\n",
       "502  0.120722   0.0  76.7  2.652694  282.0  20.6\n",
       "503  0.226099   0.0  91.0  2.348891  284.0  23.9\n",
       "504  0.139833   0.0  89.3  2.783274  275.0  22.0\n",
       "505  0.183073   0.0  80.8  2.847304  283.0  11.9\n",
       "\n",
       "[506 rows x 6 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will go back to the original data file, and divide the whole set into training and testing sets. \n",
    "np.random.seed(seed=13579)\n",
    "\n",
    "train = {'CRIM': data[:,0],'ZN': data[:,1], 'RM': data[:,5],'RM': data[:,6],'DIS': data[:,7],'TAX': data[:,9]}\n",
    "test = {'MEDV': target}\n",
    "KFold_train = pd.DataFrame(data=train)\n",
    "KFold_test = pd.DataFrame(data=test)\n",
    "KFold_train_norm = KFold_train.copy()\n",
    "KFold_test_norm = KFold_test.copy()\n",
    "for col in KFold_train_norm.columns:\n",
    "    KFold_train_norm[col] = normalize(KFold_train[col])\n",
    "for col in KFold_test_norm.columns:\n",
    "    KFold_test_norm[col] = normalize(KFold_test[col])\n",
    "\n",
    "KFold_train[\"MEDV\"]= KFold_test[\"MEDV\"]\n",
    "\n",
    "KFold_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_RMSE_means = np.zeros(25)\n",
    "\n",
    "for i in range(25):\n",
    "    RMSE_mean, t = knneighbor(CV_train[['CRIM','ZN','RM','DIS','TAX']],CV_train['MEDV'],CV_train['fold_number'] 2, 3)\n",
    "    \n",
    "    K_RMSE_means[i] = RMSE_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(1,26), K_RMSE_means, c='C0',)\n",
    "plt.title(\"Scatter plot for RMSE compared to value for K\")\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"RMSE value\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph, we see that our minimum value for K is when K = 4. When see that RMSE initially decreases when K goes from 1 to 4, and increases when K goes from 4 to 25. Because the RMSE value is lowest at K = 4, I believe this to be a reasonable value for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-Credit: Forward selection\n",
    "\n",
    "Thus far the choice of predictor variables has been rather arbitrary. For extra credit, implement a basic [forward selection](http://www.stat.ubc.ca/~rollin/teach/643w04/lec/node41.html) algorithm to progressively include features that decrease the cross-validated RMSE of the model. Note that the optimal value of K may be different for each model, so you may want to use cross-validation to choose K each time (but it is also fine if you fix K at the optimal value from 2.7).  Create a graph that shows RMSE as a function of the number of features in the model. Label each point on the x-axis with the name of the feature that is added at that step in the forward selection algorithm. *(For instance, if the optimal single-feature model has CRIM with RMSE = 10, and the optimal two-feature model has CRIM+ZN with RMSE=9, the first x-axis label will say CRIM and the second x-axis lable with say ZN)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
